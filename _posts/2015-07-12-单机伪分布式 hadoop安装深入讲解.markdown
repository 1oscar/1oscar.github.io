---
layout: post
title: "单机伪分布式 hadoop安装深入讲解"
comments: true
share: true
tags: hadoop
---

### 环境:  `Mac OS X Yosemite 10.10; java version 1.8.0_45；hadoop 2.7.1;`

一：配置ssh环境

1. `ssh localhost`: 提示无权限
2. 系统偏好设置－》共享－》远程登录－》所有用户
3. `ssh localhost` Ok ,but 每次输入密码麻烦
4. `cat ~/.ssh/id_rsa.pub >> authorized_keys`
5. `ssh localhost` 不用每次输入密码了

二： 配置java环境

1. `java -version`: 若没有安装java，mac下提示安装
2. 系统安装版本: 

   ```
   java version "1.8.0_45"
   Java(TM) SE Runtime Environment (build 1.8.0_45-b14)
   Java HotSpot(TM) 64-Bit Server VM (build 25.45-b02, mixed mode)
   ```

三： 安装homebrew

1. homebrew is OS X 下套件管理器
2. ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"
3. 按回车键继续下一步
4. `brew -version` 查看版本号: `Homebrew 0.9.5`

四: 安装hadoop

1. brew install hadoop
2. 我的系统版本： 2.7.1

五: 修改配置

1. `cd /usr/local/Cellar/hadoop/2.7.1/libexec/etc/hadoop`
2. `vi hadoop-env.sh` 修改为
   ```
   export HADOOP_OPTS="$HADOOP_OPTS -Djava.net.preferIPv4Stack=true -Djava.security.krb5.realm= -Djava.security.krb5.kdc="
   export JAVA_HOME="/Library/Java/JavaVirtualMachines/jdk1.8.0_45.jdk/Contents/Home/"
   ```

3. `vi core-site.xml`: 
   
   ```
     19 <configuration>
     20      <property>
     21         <name>hadoop.tmp.dir</name>
     22         <value>/usr/local/Cellar/hadoop/hdfs/tmp</value>
     23         <description>A base for other temporary directories.</description>
     24     </property>
     25     <property>
     26         <name>fs.default.name</name>
     27         <value>hdfs://localhost:9000</value>
     28     </property>
     29 </configuration>
   ```
注： fs.default.name 保存了NameNode的位置，HDFS和MapReduce组件都需要用到它，这就是它出现在core-site.xml 文件中而不是 hdfs-site.xml文件中的原因

4. `vi hdfs-site.xml`
   
   ```
       19 <configuration>
       20     <property>
       21         <name>dfs.replication</name>
       22         <value>1</value>
       23     </property>
       24 </configuration>
   ```
 变量dfs.replication指定了每个HDFS数据库的复制次数。 通常为3, 由于我们只有一台主机和一个伪分布式模式的DataNode，将此值修改为1。  

5. ` vi mapred-site.xml.template `

 ```
  19 <configuration>
  20     <property>
  21         <name>mapreduce.framework.name</name>
  22         <value>yarn</value>
  23     </property>
  24 </configuration>
 ```
 变量mapred.job.tracker 保存了JobTracker的位置，因为只有MapReduce组件需要知道这个位置，所以它出现在mapred-site.xml文件中。
 
6. `vi yarn-site.xml  `

   ```
    18 <configuration>
    19     <property>
    20         <name>yarn.nodemanager.aux-services</name>
    21         <value>mapreduce_shuffle</value>
    22     </property>
    23 </configuration>
   ```

7. `cd /usr/local/Cellar/hadoop/2.6.0/bin`
8. `hadoop namenode -format`  启动hadoop之前要先格式化 hdfs

六： `cd /usr/local/Cellar/hadoop/2.6.0/sbin`

1. `start-dfs.sh  ` : 启动NameNode daemon and DataNode daemon
   出现一个 警告：WARN
 util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable 这对Hadoop的运行没有影响,警告 是关于 Hadoop 本地库的， Hadoop本地库是为了提高效率或者某些不能用Java实现的功能组件库。其解决方法是 [Mac
 OSX 下 Hadoop 使用本地库提高效率](http://rockyfeng.me/hadoop_native_library_mac.html)
2. `stop-dfs.sh`    ： 停止hdfs
3.  展现： http://localhost:50070/
4. `start-yarn.sh`   :ResourceManager daemon and NodeManager daemon
5. 展现： http://localhost:8088/     #JobTracker:
5. Specific Node Information: http://localhost:8042
6. `start-all.sh`  启动所有
 
