---
layout: post
title: "逻辑回归的怪圈子" 
comments: true
share: true
tags: 算法
---

为啥叫他怪圈子？因为本文将会从逻辑回归出发，看其是如何串起几乎涵盖了所有的机器学习等相关领域算法的圈子，当然最主要的还是深入讲解逻辑回归，本文便是从0到1的过程。

一：<br>
逻辑回归本身还是属于分类领域的算法之一，相关的其他分类算法如决策树，knn，navie byes，神经网络，random forest，svm等等，这些算法都有一个共同的
特性，就是需要通过训练集训练，然后再通过测试集测试。这中间就会出现过拟合的现象，如何防止过拟合，如何防止欠拟合，即 variance和bias之间的关系的校准，这是
一个老大难的问题，不限于这些算法会用到，在推荐领域，DM领域，ML领域，ADS领域会涉及的比较多。而从分类算法出发，看他对立的小圈子无监督学习等，又包含了聚类，
关联等等算法，聚类的算法又包含很多，关联的算法现在市面上用的也非常频繁。经常与监督学习，无监督学习一起谈论的，就有强化学习，水还是比较深的。同时，由分类算法
等联系到的各种优化算法，涉及到的数学知识如概率论，线代，凸优化等，其中凸优化这本书科班出身的研究生课程应该都有学过，理论概念很强烈。说到这个优化算法，想起我在
知乎上的一则答案，即所有的算法问题都可以转成优化问题，可见其强大的功能。

上面只是一则回忆，下面才是正题。（下面不会解释那么多了，个中联系自己领悟，均可从LR找到他们的影子）

对于 目标优化函数:<br>
square cost function -->线性回归<br>
log cost function   -->  LR<br>
exp cost function   --> bossting<br>
hinge cost function --> svm

而上面四种算法本质都是可以转化为凸优化问题，即将cost function转为凸函数，求极值等，具体的方法如牛顿，gauss 牛顿， 拟牛顿，SGA(SGD)，bfgs，l-bfgs
等等。

二：

逻辑回归适用于二分类情况，那么针对多分类情况用softmax regression。

逻辑function：<br>
![预测(LR)函数](http://1oscar.github.io/photos/blogPhotos/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%80%AA%E5%9C%88%E5%AD%90/1.png)

其中，指数表示：<br>
![参数含义](http://1oscar.github.io/photos/blogPhotos/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%80%AA%E5%9C%88%E5%AD%90/2.png)

如下图，表示成概率形式，z是决策边界（阈值），阈值>=0.5,y=1,z<0.5,y=0  -->LR也是一种概率估计。<br>
![图形](http://1oscar.github.io/photos/blogPhotos/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%80%AA%E5%9C%88%E5%AD%90/3.png)

补充：lr本质是线性回归，但是线性回归的cost function拟合lr data，图形是非凸的，即波浪线的凹形图，而用lr cost function（凸函数）拟合lr data，是凸状的。
，所以这里采用构造对数函数，使其lr的cost 变为凸函数，这也是凸优化的一个过程。

凸函数：局部最小值即全局最小值。

用概率公式来表示：<br>
![lr概率](http://1oscar.github.io/photos/blogPhotos/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%80%AA%E5%9C%88%E5%AD%90/4.png)

上面那概率是否眼熟，伯努利分布，可以合并。<br>
构造似然函数：<br>
![似然函数](http://1oscar.github.io/photos/blogPhotos/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%80%AA%E5%9C%88%E5%AD%90/5.png)

取对数likehood：<br>
![loglikehood](http://1oscar.github.io/photos/blogPhotos/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%80%AA%E5%9C%88%E5%AD%90/6.png)

构造真正的lr损失函数时候，需要表示成如下所示<br>
![损失函数](http://1oscar.github.io/photos/blogPhotos/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%80%AA%E5%9C%88%E5%AD%90/7.png)

符号为求最小值，这等同于最大似然时求最大value。<br>
1/m系数一说是求平均损失，一说是为了简化公式化简过程，从后面最终求偏导的结果在真正的代码中实现时没有加入情况来看，应该是偏向于后者，化简过程。

注：在统计学中，最大似然估计是求参数最大值。机器学习中，损失函数是求最小值。

三：优化方法

梯度下降：

求损失函数最小值（若是求对数似然函数的最大值，用的是梯度上升法，其结果与求损失函数最小值的结果是一样，在机器学习实战中使用的便是梯度上升）

参数的更新过程，这里alpha是学习步长：<br>
![参数更新过程](http://1oscar.github.io/photos/blogPhotos/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%80%AA%E5%9C%88%E5%AD%90/8.png)

参数求偏导后的最终结果如下：<br>
![最终结果](http://1oscar.github.io/photos/blogPhotos/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%80%AA%E5%9C%88%E5%AD%90/9.png)

上述公式结果的系数1/m一般在代码中会去掉。<br>
上面结果公式翻译成中文就是：下一个值 = 当前值+步长*方向

注：步长的选择还是很重要的，步长过小，损失函数下降慢。关于步长选择的不同带来的影响如下图：<br>
![步长选择](http://1oscar.github.io/photos/blogPhotos/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%80%AA%E5%9C%88%E5%AD%90/10.png)

关于如何选择步长的小trick：先选较小的步长如0.001,然后以三倍的方式增加步长尝试效果。

关于梯度上升的代码以及优化的SGA和改进的SGA代码可参见exercises/machine learning/LR

注：

从改进的SGA代码里可以看出：

1) alpha虽迭代次数不断下降，不断->0.01,0.01存在原因是多次迭代后新数据仍有一定的影响。<br>
2) random select 样本update regression 系数时候，减少周期性的波动

除了上述针对损失函数的优化之外，还有拟牛顿，BFGS，L-BFGS，共轭函数等方法，这些方法优点是：<br>
1)不需要手动选择步长<br>
2)比GA算法快，因为真实的GA算法是需要不断地遍历整个样本。

在真是的求解过程中，若样本数值很大，需要先进行归一化处理，使得样本数值属于0-1之间。

下面介绍几种归一化的方法<br>
1) feature value/feature max value  <br>
2) 均值归一化： （feature -该组特征值mean value)/该组feature max value   <br>
3) 最合理的做法是： x = (x-u)/delta   <br>
即（当前组的特征-该组特征均值）/标准差或者特征范围(最大的value-最小的value)

上面补充了那么多，下面说说一些缺陷与对比吧:

1) GA算法缺陷：每次update回归系数遍历整个数据集，改进后的SGA属于在线学习算法的一种（类似FTRL），这里SGA一次仅用一个样本点更新回归系数（这点
从代码上很容易看出来），SGA适用于比较打的训练集合的case。<br>

SGA与GA的区别（代码层面）：<br>
1) SGA中h和error都是数值，GA都是向量   <br>
2) SGA无矩阵转换过程，所有变量类型都是NUMPY数组。

四：总结

1) LR目的：找一个非线性函数H(x)的最佳拟合函数参数ceta   <br>
2) 求解用最优化算法fihish       <br>
3) 最优化算法中常用GA（改进为SGA）
4) 判断优化算法优劣可靠办法：是否收敛即参数是否稳定


ps：我终于明白了美团那个熊孩子讲的ga是啥意思了

五：提升  

但凡监督学习均可看做最小化下面目标function的过程：<br>
![最小化目标函数](http://1oscar.github.io/photos/blogPhotos/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%80%AA%E5%9C%88%E5%AD%90/11.png)

上述公式第一部分是：模型用来拟合data，第二部分是规则化函数，用来约束模型。

关于规则化函数，又叫做正则化。

p=1,叫做L1正则化，产生稀疏解，应用广泛。  <br>
p=2,叫做L2正则化。<br>
关于这两个正则化图形，会发现L1正则会使特征处于坐标轴上，这样会使为0，所以有利于稀疏。：<br>
![L1,L2比较](http://1oscar.github.io/photos/blogPhotos/%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E7%9A%84%E6%80%AA%E5%9C%88%E5%AD%90/12.png)

文字描述关于L1,L2的比较:  <br>
1) L0,L1范数均可实现稀疏行，但L1比L0有更好的优化求解特性，应用广泛。<br>
2) L1别名稀疏规则算子，算是解释其稀疏特性功能了吧。L1范数是指向量中各元素的绝对值之和。<br>
3) L1可稀疏指可使得参数矩阵w的大部分特征之和为0。  <br>
4) L2范数又叫（Ridge回归）岭回归或者权值衰减，即向量中各元素平方和再求平方根。（作用防止过拟合，起到简化模型作用)

参数稀疏好处：<br>
1) 特征选择： 实现特征自动选择，自动去掉无用的信息特征，即特征对应权重为0）  <br>
2) 可解释性:把高维的数据中无用特征去掉，分析模型表现的现实意义原因时集中在有用的几个特征里。

讲了那么多，是不是有点晕乎，其实就一句话：

L1趋向于产生少量特征，而其他特征为0；L2会选择更多的特征，使其接近于0;L1在特征选择时有用，而L2是一种规则化而已。

关于特征这点，spark mlib的卡方选择器或许也是另一种思路。

